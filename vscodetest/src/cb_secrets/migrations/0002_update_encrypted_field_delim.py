# Generated by Django 3.2.3 on 2021-09-13 15:14
import hashlib
import os
import pwd
import math
import errno
import sys
from base64 import b64encode, b64decode
from django.db import connection, migrations
from django.db.utils import OperationalError, ProgrammingError
from django.conf import settings
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes, atfork
from utilities.logger import ThreadLogger

atfork()  # Support parallel unit tests! Required in any module where Crypto.Random is being used.
logger = ThreadLogger(__name__)

update_metadata = [
    {"model_name": "ConnectionInfo", "table_name": "utilities_connectioninfo", "column_name": "password", "id_column_name": "id"},
    {"model_name": "ConnectionInfo", "table_name": "utilities_connectioninfo", "column_name": "headers", "id_column_name": "id"},
    {"model_name": "GlobalPreferences", "table_name": "utilities_globalpreferences", "column_name": "smtp_password", "id_column_name": "id"},
    {"model_name": "LDAPUtility", "table_name": "utilities_ldaputility", "column_name": "servicepasswd", "id_column_name": "id"},
    {"model_name": "RADIUSUtility", "table_name": "utilities_radiusutility", "column_name": "secret", "id_column_name": "id"},
    {"model_name": "StoredSSHKey", "table_name": "utilities_storedsshkey", "column_name": "private_key", "id_column_name": "sshkey_ptr_id"},
    {"model_name": "ExportPassword", "table_name": "cb_secrets_exportpassword", "column_name": "password", "id_column_name": "id"},
    {"model_name": "PEConf", "table_name": "puppet_ent_peconf", "column_name": "ssl_private_key", "id_column_name": "connectorconf_ptr_id"},
    {"model_name": "DataProtection", "table_name": "dataprotection_dataprotection", "column_name": "servicepasswd", "id_column_name": "id"},
    {"model_name": "IPAM", "table_name": "ipam_ipam", "column_name": "servicepasswd", "id_column_name": "id"},
    {"model_name": "ITSM", "table_name": "itsm_itsm", "column_name": "password", "id_column_name": "id"},
    {"model_name": "HookParameters", "table_name": "jobs_hookparameters", "column_name": "_encrypted_arguments", "id_column_name": "jobparameters_ptr_id"},
    {"model_name": "TriggerActionParameters", "table_name": "jobs_triggeractionparameters", "column_name": "_encrypted_arguments", "id_column_name": "jobparameters_ptr_id"},
    {"model_name": "TriggerParameters", "table_name": "jobs_triggerparameters", "column_name": "_encrypted_arguments", "id_column_name": "jobparameters_ptr_id"},
    {"model_name": "NetworkVirtualization", "table_name": "network_virtualization_networkvirtualization", "column_name": "servicepasswd", "id_column_name": "id"},
    {"model_name": "OrchestrationEngine", "table_name": "orchestrationengines_orchestrationengine", "column_name": "servicepasswd", "id_column_name": "id"},
    {"model_name": "CustomFieldValue", "table_name": "orders_customfieldvalue", "column_name": "pwd_value", "id_column_name": "id"},
    {"model_name": "ProvisionNetworkOrderItem", "table_name": "jobs_hookparameters", "column_name": "_encrypted_arguments", "id_column_name": "jobparameters_ptr_id"},
    {"model_name": "ActionJobOrderItem", "table_name": "orders_actionjoborderitem", "column_name": "_encrypted_arguments", "id_column_name": "orderitem_ptr_id"},
    {"model_name": "ProvisionEngine", "table_name": "provisionengines_provisionengine", "column_name": "servicepasswd", "id_column_name": "id"},
    {"model_name": "ResourceHandler", "table_name": "resourcehandlers_resourcehandler", "column_name": "servicepasswd", "id_column_name": "id"},
    {"model_name": "AlibabaResourceHandler", "table_name": "alibaba_alibabaresourcehandler", "column_name": "access_key_secret", "id_column_name": "resourcehandler_ptr_id"},
    {"model_name": "AWSHandler", "table_name": "aws_awshandler", "column_name": "billingpasswd", "id_column_name": "resourcehandler_ptr_id"},
    {"model_name": "AzureARMHandler", "table_name": "azure_arm_azurearmhandler", "column_name": "secret", "id_column_name": "resourcehandler_ptr_id"},
    {"model_name": "AzureStackHandler", "table_name": "azure_arm_azurearmhandler", "column_name": "secret", "id_column_name": "resourcehandler_ptr_id"},
    {"model_name": "GCPHandler", "table_name": "gcp_gcphandler", "column_name": "web_client_json", "id_column_name": "resourcehandler_ptr_id"},
    {"model_name": "GCPHandler", "table_name": "gcp_gcphandler", "column_name": "gcp_api_credentials", "id_column_name": "resourcehandler_ptr_id"},
    {"model_name": "GCPProject", "table_name": "gcp_gcpproject", "column_name": "billing_account_key", "id_column_name": "id"},
    {"model_name": "ReportingEngine", "table_name": "reportengines_reportingengine", "column_name": "servicepasswd", "id_column_name": "id"},
    {"model_name": "WebHook", "table_name": "cbhooks_webhook", "column_name": "http_password", "id_column_name": "orchestrationhook_ptr_id"},
    {"model_name": "ServiceBlueprint", "table_name": "servicecatalog_serviceblueprint", "column_name": "remote_source_password", "id_column_name": "id"},
    {"model_name": "SplunkProvider", "table_name": "splunk_splunkprovider", "column_name": "password", "id_column_name": "siemprovider_ptr_id"},
    {"model_name": "ContainerOrchestrator", "table_name": "containerorchestrators_containerorchestrator", "column_name": "servicepasswd", "id_column_name": "id"},
    {"model_name": "Kubernetes", "table_name": "kuberneteshandler_kubernetes", "column_name": "cert_file_contents", "id_column_name": "containerorchestrator_ptr_id"},
    {"model_name": "Kubernetes", "table_name": "kuberneteshandler_kubernetes", "column_name": "key_file_contents", "id_column_name": "containerorchestrator_ptr_id"},
    {"model_name": "Kubernetes", "table_name": "kuberneteshandler_kubernetes", "column_name": "ca_file_contents", "id_column_name": "containerorchestrator_ptr_id"},
    {"model_name": "ModuleCredential", "table_name": "module_credentials", "column_name": "password", "id_column_name": "id"}
]


# The function and constants below were copied from cb_secrets/crypto.py to maintain consitency for this migration.

# block size of our cipher in bytes.
# 16 is the default for our AES library.
BLOCK_SIZE = 16

# a 16*8 = 128 bit key
KEY_SIZE = 16

# Set the delimiter for encrpyted fields.
CB_DELIM = bytes("<CB_DELIM>", "utf-8")


def get_or_create_key():
    """
    Return the encryption key that is stored in /var/opt/cloudbolt/secrets/, or
    if the key does not exist yet, create and save one and then return it.
    """
    CONF = getattr(settings, "SECRETS", {})

    if "OWNER" in CONF:
        owner_name = CONF["OWNER"]
        owner_uid = pwd.getpwnam(owner_name).pw_uid
        owner_gid = pwd.getpwnam(owner_name).pw_gid
    else:
        # get the uid and login name of the currently effective user
        # http://docs.python.org/2/library/os.html#os.getlogin
        owner_uid = os.getuid()
        owner_gid = os.getgid()
        owner_name = pwd.getpwuid(owner_uid).pw_name

    # we add the owner to the key's filename so that each user can have
    # their own locked-down file (primarily useful in a shared environment)
    key_path = os.path.join(
        settings.VARDIR,
        "opt/cloudbolt/secrets/secret-key-for-{}.bin".format(owner_name),
    )
    key_dir = os.path.dirname(key_path)

    # When we create files, we make sure to explicitly set the minimum
    # permissions, so we ensure the umask doesn't remove any of them by setting
    # it to zero. For example, when creating the secrets directory with 0777, a
    # typical default umask of 0002 yields a final permission of 0775, which
    # has a necessary write permission removed.
    original_umask = os.umask(0)

    # we expect /var/opt/cloudbolt/ already exists, and will try to create the
    # 'secrets' subdirectory if it doesn't already exist.
    if not os.path.isdir(key_dir):
        try:
            # There may be multiple instances of CB running on a single server.
            # By setting the secrets dir world-read/writeable we permit other
            # users to add their own secret keys.
            os.mkdir(key_dir, 0o777)
        except OSError as e:
            logger.error(
                "The directory '{}' does not exist and could not be "
                "created.".format(key_dir)
            )
            raise e

    try:
        with open(key_path, "rb") as key_file:
            key = key_file.read()
            if len(key) != KEY_SIZE:
                logger.error(
                    _(
                        "The key file at '{key_path}' does not contain a valid key."
                    ).format(key_path=key_path)
                )
                sys.exit(1)
    except IOError as e:
        if e.errno == errno.ENOENT:
            # the file does not yet exist, so we create it
            logger.info(
                _(
                    "Key file for user {owner_name} does not exist. Will create a new one."
                ).format(owner_name=owner_name)
            )

            key = get_random_bytes(KEY_SIZE)

            try:
                key_file = open(key_path, "wb")
                fd = key_file.fileno()

                os.fchown(fd, owner_uid, owner_gid)
                os.fchmod(fd, 0o200)

                # Now that we've locked down the file to owner write-only, we
                # can write the key without having to worry about others being
                # able to peek at the file before we set it's final owner
                # read-only permissions.
                key_file.write(key)

                # we need to flush before we remove the write permission,
                # because our write could be buffered and not happen until
                # we no longer have permission to write (and then we'd have an
                # empty key file).
                key_file.flush()

                # Now we set the file to owner|group read-only to protect people
                # against accidentally clobbering the key and losing everyone's
                # encrypted data
                os.fchmod(fd, 0o440)

            except (IOError, OSError):
                logger.error(_("Could not create key file."))
                # something went wrong while creating the key file, so we try
                # to delete it (otherwise we might leave an empty file around).
                os.remove(key_path)
                # our error handling isn't detailed enough to describe the
                # exact problem, so we re-raise the error to get traceback.
                raise

            else:
                key_file.close()

        else:
            # we handled the file-does-not-exist case in the 'if' block, but we
            # don't know how to handle the other cases AKA this 'else' block.
            logger.error(
                _("Could not read the secret key file '{key_path}'.").format(
                    key_path=key_path
                )
            )
            raise e

    # play nice and set the umask to how we originally found it
    os.umask(original_umask)

    return key


KEY = get_or_create_key()


def pad(text: bytes):
    """Pad a bytestring to be multiples of `BLOCK_SIZE` in length"""
    n = BLOCK_SIZE - (len(text) % BLOCK_SIZE)
    return text + bytes([n]) * n


def unpad(text: bytes):
    """Undo `pad`"""
    try:
        n = ord(text[-1])
    except TypeError:
        # ord() expected string of length 1, but int found
        n = text[-1]
    return text[:-n]


def create_iv() -> bytes:
    """
    Return a new and random initialization vector
    """
    return get_random_bytes(BLOCK_SIZE)


def create_cipher(iv, password: str = None):
    """
    Return an AES cipher initialized with the given IV.

    The cipher's key is automatically specified (and persistent across
    invocations).
    """

    if password:
        pwd_bytes = bytes(password, encoding="utf-8")
        # Convert to a 16-byte hash of the password, using the sha512 hash algorithm
        # and indexing just the first 16-bytes for our AES BLOCK_SIZE.
        symm_key = hashlib.sha512(pwd_bytes).digest()[:BLOCK_SIZE]

    else:
        # Default Key
        symm_key = KEY

    return AES.new(symm_key, AES.MODE_CBC, iv)


def encrypt_text(value: str, password: str = None) -> str:
    """
    Starting with a str value, encrypt it and return the encrypted
    string which can be used as the stored db value for our EncryptedTextFields
    or exported in a blueprint.
    """
    # Convert the plaintext to utf-8 bytes
    value = bytes(value, "utf-8")

    # Encrypt the plaintext and save the iv that was generated
    ciphertext, iv = encrypt(value, password)

    # Encode ciphertext and iv using base64
    b64_ciphertext, b64_iv = b64encode(ciphertext), b64encode(iv)

    # Join the base64-encoded bytestrings with a null byte
    db_value = b64_ciphertext + CB_DELIM + b64_iv

    # Convert the bytes to str
    encrypted_text = db_value.decode()

    return encrypted_text


def encrypt(plaintext: bytes, password: str = None):
    """
    Return a tuple of the encrypted value of `plaintext` and the IV used for
    the encryption.

    The IV is random each time.
    """
    iv = create_iv()
    cipher = create_cipher(iv, password)

    ciphertext = cipher.encrypt(pad(plaintext))
    return ciphertext, iv


def decrypt(ciphertext, iv, password: str = None):
    """
    Decrypt `ciphertext` using the given `iv` and return the plaintext.
    """
    cipher = create_cipher(iv, password)
    plaintext = unpad(cipher.decrypt(ciphertext))
    return plaintext


class Migration(migrations.Migration):
    def update_encrypted_fields_delim(apps, schema_editor):
        with connection.cursor() as cursor:
            for data in update_metadata:
                batch_size = 1500
                cursor.execute(f"SELECT count(1) FROM {data['table_name']} WHERE {data['column_name']} IS NOT NULL")
                rows = cursor.fetchall()

                batches = math.ceil((rows[0][0] / batch_size))
                total_decode_errs = 0
                total_errors = 0
                update_count = 0
                for batch_idx in range(batches):
                    offset = batch_idx * batch_size
                    cursor.execute(f"SELECT {data['id_column_name']}, {data['column_name']} FROM {data['table_name']} WHERE {data['column_name']} IS NOT NULL ORDER BY {data['id_column_name']} LIMIT %s OFFSET %s", (batch_size, offset))
                    rows = cursor.fetchall()

                    update_batch = list()
                    for row in rows:
                        encrypted_text = bytes(row[1], "utf-8")
                        if b"\0" not in encrypted_text:
                            continue

                        # Extract the base64-encoded ciphertext and iv (initialization vector) from the
                        # bytestring
                        # b64_ciphertext, b64_iv = encrypted_text.split(b"\0")
                        b64_ciphertext, b64_iv = encrypted_text.split(b"\0")

                        # Undo the base64 encoding
                        ciphertext, iv = b64decode(b64_ciphertext), b64decode(b64_iv)

                        # Decrypt the ciphertext using the iv
                        decrypted_bytes = decrypt(ciphertext, iv, password=None)

                        try:
                            # Convert the utf-8 encoded bytes to str
                            decrypted_text = decrypted_bytes.decode("utf8")
                        except UnicodeDecodeError:
                            total_decode_errs += 1
                        except Exception:
                            total_errors += 1
                        else:
                            encrypted_text = encrypt_text(decrypted_text)
                            update_batch.append((encrypted_text, row[0]))

                    if update_batch:
                        try:
                            cursor.executemany(f"UPDATE {data['table_name']} SET {data['column_name']} = %s WHERE {data['id_column_name']} = %s", update_batch)
                        except (OperationalError, ProgrammingError, Exception) as e:
                            print(f"Error table name {data['table_name']} id_column_name: {data['id_column_name']} column_name: {data['column_name']} Error: {str(e)}")
                            raise e
                        else:
                            update_count += len(update_batch)

                if total_decode_errs > 0:
                    print(f"WARNING Unicode Decode Errors on {data['table_name']}: {total_decode_errs}")

                if total_errors > 0:
                    print(f"WARNING Other Decryption Errors on {data['table_name']}: {total_errors}")

    dependencies = [
        ('cb_secrets', '0001_initial'),
        ('utilities', '0115_merge_20210810_1751'),
        ('puppet_ent', '0006_auto_20170120_2337'),
        ('dataprotection', '0006_auto_20210622_0122'),
        ('ipam', '0010_set_global_id_for_ipam'),
        ('itsm', '0006_auto_20210108_1812'),
        ('jobs', '0052_remove_unencrypted_arguments'),
        ('network_virtualization', '0010_set_global_id_for_networkvirtualizationtechnology'),
        ('orchestrationengines', '0005_set_global_id_for_orchestrationengine'),
        ('orders', '0041_alter_customfieldvalue_url_value'),
        ('provisionengines', '0006_remove_cobbler'),
        ('resourcehandlers', '0029_set_global_id_for_resource_network'),
        ('alibaba', '0004_alibabaserverinfo_disk_category'),
        ('aws', '0020_merge_20210319_1539'),
        ('azure_arm', '0052_auto_20210219_1454'),
        ('gcp', '0021_merge_20210908_1751'),
        ('reportengines', '0001_initial'),
        ('cbhooks', '0091_auto_20210820_2054'),
        ('servicecatalog', '0073_auto_20210831_1746'),
        ('splunk', '0007_auto_20190802_1756'),
        ('containerorchestrators', '0012_merge_20210217_2100'),
        ('kuberneteshandler', '0009_auto_20191204_2219'),
        ('credentials', "0003_modulecredential_connection_method"),
    ]

    operations = [
        migrations.RunPython(update_encrypted_fields_delim, migrations.RunPython.noop),
    ]
